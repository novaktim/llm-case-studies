# Automated Data Analysis using Large Language Models
## Overview
This repository contains the implementation of an automated data analysis framework powered by Large Language Models (LLMs) to streamline model development and evaluation, with a specific application to the Spaceship Titanic Kaggle competition. The framework automates several key aspects of the data analysis pipeline, including feature engineering, model selection, cross-validation, and hyperparameter tuning. It integrates external knowledge retrieval from web sources to enhance contextual understanding, improving predictive performance.
## Key highlights
- Automated Data Analysis: The system automatically analyzes dataset characteristics to generate structured prompts for data processing tasks.
- Feature Engineering: Combines traditional techniques with LLM-driven AI-generated features to enhance predictive modeling.
- Model Development & Evaluation: Facilitates model selection, hyperparameter tuning, and evaluation without manual intervention.
- External Knowledge Integration: Retrieves relevant web-based insights to improve the understanding of the dataset.
- Use Case: Applied to the Spaceship Titanic competition, the framework successfully automated the entire data analysis pipeline, providing a baseline for model development that can be applied to other Kaggle competitions or machine learning tasks.
### Acknowledgments
This work was presented at DEXA 2025 (The 27th International Conference on Big Data Analytics and Knowledge Discovery) and is part of the DAWAK 2025 track.
### Authors
Vincent Schroeder, Tim Novak, Ahmed Arian Sajid, Gaurav Saraswat, Hussain
Sabir, Mustaali Hussain, Syed Bilal Salim, MD Burhanur Rashid, Tejaswini
Prashar, Arda Kocaman, Purvanshi Sharma, Dhanya Zacharias, Simon
Klüttermann, and Emmanuel Müller

Technical University of Dortmund
